{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91802f7b-2f5c-47b8-b9ce-bebd2e3e78b5",
   "metadata": {},
   "source": [
    "# Dynamic Web scraper\n",
    "\n",
    "This notebook scrapes the MSU courses website. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3446b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load selinimum and automatically install the Chrome Driver\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from getpass import getpass\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79409084-ca62-4557-b055-6666e71f0dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chrome Driver\n",
    "options = webdriver.ChromeOptions()\n",
    "driver = webdriver.Chrome(options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db2164d-feef-4acd-9efa-687cb506c16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FireFox Driver\n",
    "# driver = webdriver.Firefox()\n",
    "# time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50494a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://student.msu.edu/psc/public/EMPLOYEE/SA/c/NUI_FRAMEWORK.PT_AGSTARTPAGE_NUI.GBL?CONTEXTIDPARAMS=TEMPLATE_ID%3aPTPPNAVCOL&scname=MSU_AA_SCHEDULE_NEW0&PanelCollapsible=Y\"\n",
    "driver.get(url)\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5589cb6-d5ef-496c-8aa9-e2cd90e518b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "body = driver.page_source\n",
    "soup = BeautifulSoup(body, 'html.parser')\n",
    "cells = soup.find_all(\"tr\", class_=\"ps_grid-row psc_rowact\") # Find all table row in the page (Semesters)\n",
    "semesters = dict()\n",
    "\n",
    "for cell in cells:\n",
    "    semester = cell.find(\"a\", class_=\"ps-link\")\n",
    "    semesters[semester.text] = semester.get(\"href\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee77f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = semesters[\"Fall Semester 2024\"]\n",
    "driver.execute_script(url);\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2741da",
   "metadata": {},
   "outputs": [],
   "source": [
    "element = driver.find_element(By.ID, 'MSU_CLSRCH_WRK2_SUBJECT')  \n",
    "element.send_keys(\"CMSE\") #pick cmse for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4c4c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"javascript:submitAction_win0(document.win0,'MSU_CLSRCH_WRK_SSR_PB_SEARCH');\"\n",
    "driver.execute_script(url);\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86be9395",
   "metadata": {},
   "source": [
    "Function to get basic classes' info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169d588e-936d-4421-9d7b-17c179155808",
   "metadata": {},
   "outputs": [],
   "source": [
    "body = driver.page_source\n",
    "soup = BeautifulSoup(body, 'html.parser')\n",
    "\n",
    "# get the number of results\n",
    "result_element = soup.find('span', id='MSU_RSLT_NAV_WK_PTPG_ROWS_GRID')\n",
    "# Extract the text content\n",
    "result_text = result_element.get_text(strip=True)\n",
    "result = int(result_text.split()[0])\n",
    "pages = (result + 49) // 50# get the number of aggregated pages\n",
    "\n",
    "def get_class_info(soup):\n",
    "    '''Scrape entire page for all of the class boxes'''\n",
    "    \n",
    "    reshaped_list = []\n",
    "    cells = soup.find_all(\"tr\", class_=\"ps_grid-row psc_rowact\") # Find all table row in the page (Classes)\n",
    "    if pages > 1:\n",
    "        for i in range(pages - 1):\n",
    "            url = f\"javascript:submitAction_win0(document.win0,'MSU_RSLT_NAV_WK_SEARCH_CONDITION2$46$');\"\n",
    "            driver.execute_script(url)\n",
    "            time.sleep(5)\n",
    "            body = driver.page_source\n",
    "            next_soup = BeautifulSoup(body, 'html.parser')\n",
    "            cells += next_soup.find_all(\"tr\", class_=\"ps_grid-row psc_rowact\")\n",
    "    \n",
    "    for cell in cells:\n",
    "        values = cell.text.split(\"\\n\") # Split text in a cell \n",
    "        values = list(filter(lambda x: x != \"\", values))  \n",
    "        values.pop()\n",
    "        brs = cell.find_all(\"br\") # Find classes that have two class time\n",
    "        if brs: # Update class with two class time\n",
    "            values[-2] = brs[0].previous_sibling.text.strip() + \"\\n\" + brs[0].next_sibling.text.strip()\n",
    "            values[-1] = brs[1].previous_sibling.text.strip() + \"\\n\" + brs[1].next_sibling.text.strip()\n",
    "        reshaped_list.append(values)\n",
    "        \n",
    "    # Create a DataFrame from the reshaped list\n",
    "    col_names = ['Course', 'Type', 'Section', 'Schedule', 'Dates']\n",
    "    df = pd.DataFrame(reshaped_list, columns=col_names)\n",
    "\n",
    "    # Deal with classes with two class time\n",
    "    for index, row in df.iterrows():\n",
    "        if \"\\n\" in row['Schedule']:\n",
    "            if \"To Be Announced\" in row['Schedule']:\n",
    "                df.loc[index, 'Schedule'] = row['Schedule'].partition(\"\\n\")[0]\n",
    "                df.loc[index, 'Dates'] = row['Dates'].partition(\"\\n\")[0]\n",
    "                \n",
    "    df[['Days', 'Time']] = df['Schedule'].str.split(':',n=1,expand=True)\n",
    "    subdf = df[df['Schedule'].apply(lambda x: \"\\n\" in x)]\n",
    "    for index, row in subdf.iterrows():\n",
    "        first_sc = row['Schedule'].partition('\\n')[0]\n",
    "        second_sc = row['Schedule'].partition('\\n')[-1]\n",
    "        df.loc[index, 'Days'] = first_sc.partition(' : ')[0] + \"\\n\" + second_sc.partition(' : ')[0]\n",
    "        df.loc[index, 'Time'] = first_sc.partition(' : ')[-1] + \"\\n\" + second_sc.partition(' : ')[-1]\n",
    "    \n",
    "    df[['Course Code', 'Course Name']] = df['Course'].str.split(':', n=1, expand=True)  \n",
    "    split_result = df['Type'].str.split('(', n=1, expand=True)\n",
    "    # Check if the split operation resulted in two columns\n",
    "    if len(split_result.columns) == 2:\n",
    "        df[['Type', 'Units']] = split_result\n",
    "    else:\n",
    "        # Handle the case where the split didn't result in two columns\n",
    "        df['Type'] = split_result[0]  # Assign the first part to 'Type'\n",
    "        df['Units'] = '' \n",
    "    df[['Section', 'Class Nbr', 'Academic Session']] = df['Section'].str.split('/', n=2, expand=True)\n",
    "    df[['Units','Status']] = df['Units'].str.split(')',n=1,expand=True)\n",
    "    df[['Subject','Course Number']] = df['Course Code'].str.split(' ',n=1,expand=True)\n",
    "    df['Dates'] = df['Dates'].apply(lambda x: x.replace(\"Approval Required\", '').strip() if x else x)\n",
    "    df['Status'] = df['Status'].str.replace('Reserved Capacity', '').str.strip()\n",
    "    \n",
    "    #df['Dates'] = df['Dates'].str.replace('Approval Required', '').str.strip()\n",
    "    df['Course Name'] = df['Course Name'].str.replace('Cross-Listed', '').str.strip()\n",
    "    df['Course Name'] = df['Course Name'].str.replace('Approval Required', '').str.strip()\n",
    "\n",
    "    df = df.drop(['Course', 'Schedule','Course Code'], axis=1)\n",
    "    df = df[['Subject','Course Number','Course Name','Type','Units','Status',\n",
    "             'Section','Class Nbr','Academic Session','Days','Time','Dates']]\n",
    "    df['Units'] = df['Units'].str.replace(' units', '')\n",
    "    df['Section'] = df['Section'].str.extract(r'(\\d+(?:\\.\\d+)?)')\n",
    "    df['Class Nbr'] = df['Class Nbr'].str.extract(r'(\\d+(?:\\.\\d+)?)')\n",
    "    return df\n",
    "\n",
    "df = get_class_info(soup)  # getting info on the first page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2af2770-3a68-4173-94f9-ad605b38c6f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Remove none\n",
    "df = df[df['Course Name'].notna()]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d20ce6-d04d-4295-b95d-ab4fc2ec3f6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"Fall2024.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19befd18-ff47-4e60-bbf6-9be100ce56cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Fall2024.csv\")\n",
    "\n",
    "url = \"https://student.msu.edu/splash.html\"\n",
    "driver.get(url)\n",
    "\n",
    "element = driver.find_element(By.ID, 'loginUrl1') \n",
    "element.click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb9bbe0-7467-4e6e-880b-eeb692019df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signing in\n",
    "element = driver.find_element(By.ID, 'input28') \n",
    "if not element.get_attribute('value'):\n",
    "    print(\"Please enter your MSU email: \")\n",
    "    email = input()\n",
    "    element.send_keys(email)\n",
    "    \n",
    "element = driver.find_element(By.ID, 'input36')  \n",
    "print(\"Please enter your password: \")\n",
    "password = getpass()\n",
    "element.send_keys(password)\n",
    "\n",
    "element = driver.find_element(By.CLASS_NAME, 'o-form-button-bar')  \n",
    "element.click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8919a8c-808e-43cc-80ea-15832d4d3c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the authentication method by phone, might not be in the right window\n",
    "# If not in the right window, click 'Verify with something else'\n",
    "buttons = driver.find_elements(By.CLASS_NAME, 'authenticator-button')\n",
    "for button in buttons:\n",
    "    if button.get_attribute('data-se') == 'phone_number':\n",
    "        button.click()\n",
    "time.sleep(5)\n",
    "\n",
    "element = driver.find_element(By.TAG_NAME, 'input')  \n",
    "element.click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f6af5a-0eff-4f74-9882-154dd00f16ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter SMS code\n",
    "element = driver.find_element(By.TAG_NAME, \"input\") \n",
    "print(\"Please enter your SMS code: \")\n",
    "code = input()\n",
    "element.send_keys(code)\n",
    " \n",
    "element = driver.find_element(By.CLASS_NAME, 'o-form-button-bar')  \n",
    "element.click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8878c5-71c9-4bea-9cfa-645ed137d8c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    element = driver.find_element(By.ID, \"win0groupletPTNUI_LAND_REC_GROUPLET$1\")  \n",
    "    element.click()\n",
    "    time.sleep(5)\n",
    "except: # In case the website want to login again\n",
    "    element = driver.find_element(By.ID, 'loginUrl1') \n",
    "    element.click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    element = driver.find_element(By.ID, \"win0groupletPTNUI_LAND_REC_GROUPLET$1\")  \n",
    "    element.click()\n",
    "    time.sleep(5)\n",
    "\n",
    "element = driver.find_element(By.ID, 'SCC_LO_FL_WRK_SCC_VIEW_BTN$2')  \n",
    "element.click()\n",
    "time.sleep(5)\n",
    "\n",
    "body = driver.page_source\n",
    "soup = BeautifulSoup(body, 'html.parser')\n",
    "cells = soup.find_all(\"tr\", class_=\"ps_grid-row psc_rowact\")\n",
    "semesters = dict()\n",
    "\n",
    "for cell in cells:\n",
    "    semester = cell.find(\"a\", class_=\"ps-link\")\n",
    "    semesters[semester.text] = semester.get(\"href\")\n",
    "\n",
    "url = semesters[\"Fall Semester 2024\"]\n",
    "driver.execute_script(url);\n",
    "time.sleep(5)\n",
    "\n",
    "element = driver.find_element(By.ID, 'MSU_CLSRCH_WRK2_SUBJECT')  \n",
    "element.send_keys(\"CMSE\") #pick cmse for example\n",
    "\n",
    "url = f\"javascript:submitAction_win9(document.win9,'MSU_CLSRCH_WRK_SSR_PB_SEARCH');\"\n",
    "driver.execute_script(url);\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ba5483-1d23-4fbd-a58e-de06009702bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "body = driver.page_source\n",
    "soup = BeautifulSoup(body, 'html.parser')\n",
    "\n",
    "# get the number of results\n",
    "result_element = soup.find('span', id='MSU_RSLT_NAV_WK_PTPG_ROWS_GRID')\n",
    "# Extract the text content\n",
    "result_text = result_element.get_text(strip=True)\n",
    "result = int(result_text.split()[0])\n",
    "pages = (result + 49) // 50# get the number of aggregated pages\n",
    "\n",
    "def get_advanced_info(soup):\n",
    "    loc = None\n",
    "    email = None\n",
    "    name = None\n",
    "    values = []\n",
    "    divs = soup.find_all(\"div\", class_=\"ps-htmlarea\")\n",
    "    for div in divs:\n",
    "        val = (div.get_text(strip=True))\n",
    "        values.append(val)\n",
    "    values = list(filter(lambda x: x != \"\", values))\n",
    "    if len(values) > 5 and values[5] != \"\":\n",
    "        string = values[5].split('Instructor:')\n",
    "    else:\n",
    "        return None, None, None\n",
    "    \n",
    "    loc = string[0]\n",
    "    a_elements = soup.find_all('a')\n",
    "    for a_element in a_elements:\n",
    "        # Check if the 'href' attribute exists\n",
    "        if 'href' in a_element.attrs:\n",
    "            # Check if the href attribute contains \"mailto:\"\n",
    "            if 'mailto:' in a_element['href']:\n",
    "                # Extract the email address from the href attribute\n",
    "                email = a_element['href'].split(':')[1]\n",
    "                name = a_element.text\n",
    "                break\n",
    "    return loc, email, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeada9c-8702-49f7-ae4c-54ff60a2e29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_info(df):\n",
    "    '''Function to add info from the breakout windows for each course\n",
    "    '''\n",
    "    location = []\n",
    "    emails = []\n",
    "    names = []\n",
    "    for i in range(pages):\n",
    "        for i in range(50):\n",
    "            try:\n",
    "                rowname = f\"DESCR100$0_row_{i}\"\n",
    "                element = driver.find_element(By.ID, rowname) \n",
    "                print(rowname)\n",
    "            except:\n",
    "                break\n",
    "            driver.execute_script(\"arguments[0].click();\", element)\n",
    "            time.sleep(5) # If too slow can change this line\n",
    "            driver.switch_to.frame(0)\n",
    "            body = driver.page_source\n",
    "            soup = BeautifulSoup(body, 'html.parser')\n",
    "            loc, email, name = get_advanced_info(soup)\n",
    "            location.append(loc)\n",
    "            emails.append(email)\n",
    "            names.append(name)\n",
    "            cancel_cmd=\"javascript:doUpdateParent(document.win9,'#ICCancel');\"\n",
    "            driver.execute_script(cancel_cmd);\n",
    "            driver.switch_to.default_content();\n",
    "            time.sleep(5) # If too slow can change this line\n",
    "        \n",
    "        if pages-1 != i:\n",
    "            url = f\"javascript:submitAction_win9(document.win9,'MSU_RSLT_NAV_WK_SEARCH_CONDITION2$46$');\"\n",
    "            driver.execute_script(url)\n",
    "            time.sleep(5)\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    df['Location'] = location\n",
    "    df['email'] = emails\n",
    "    df['Instructor'] = names\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7195633-c9d2-4bb6-9eeb-e42c88c6c7a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = add_info(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4efc555-5b9d-46e6-a967-83e91ae2cb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e917ab-93f4-4cad-b1ca-f8e2e7d24464",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Fall2024.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
