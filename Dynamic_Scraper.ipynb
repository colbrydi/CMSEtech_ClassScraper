{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91802f7b-2f5c-47b8-b9ce-bebd2e3e78b5",
   "metadata": {},
   "source": [
    "# Dynamic Web scraper\n",
    "\n",
    "This notebook scrapes the MSU courses website. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3446b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load selinimum and automatically install the Chrome Driver\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "from selenium.webdriver.chrome.service import Service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47465a6b",
   "metadata": {},
   "source": [
    "For versions of Chrome beyond 114, the WebDriver no longer has the capability to automatically retrieve a compatible version. In response, I manually acquired the WebDriver version 116 from the following website: https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/116.0.5845.96/win64/chromedriver-win64.zip. You can find additional information regarding this download on this page: https://support.google.com/chrome/thread/230521170/requires-version-116-of-the-google-chrome-driver%EF%BC%8Cplease?hl=en."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db2164d-feef-4acd-9efa-687cb506c16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup Chrome driver \n",
    "#options = Options()\n",
    "#options.add_argument('--headless')\n",
    "driver = webdriver.Firefox()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0751c3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hrome_driver_path = r'D:\\classScraper\\chromedriver-win64/chromedriver.exe'\n",
    "\n",
    "#service = Service(executable_path='D:\\classScraper\\chromedriver-win64/chromedriver.exe')\n",
    "#service = Service(executable_path='./geckodriver.exe')\n",
    "#options = webdriver.ChromeOptions()\n",
    "# running in optional headless mode\n",
    "#options.add_argument('--headless')\n",
    "# options = Options()\n",
    "# driver = webdriver.Firefox(options=options)\n",
    "# time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c015eb",
   "metadata": {},
   "source": [
    "If you have chrome version older than 115, you can use this to automatically find the compatible webdriver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8229775e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#Setup Chrome driver \n",
    "options = Options()\n",
    "options.add_argument('--headless')\n",
    "driver = webdriver.Chrome(options=options)\n",
    "time.sleep(10)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50494a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://student.msu.edu/psc/public/EMPLOYEE/SA/c/NUI_FRAMEWORK.PT_AGSTARTPAGE_NUI.GBL?CONTEXTIDPARAMS=TEMPLATE_ID%3aPTPPNAVCOL&scname=MSU_AA_SCHEDULE_NEW0&PanelCollapsible=Y\"\n",
    "driver.get(url)\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7004bf",
   "metadata": {},
   "source": [
    "The ids might change. I am using this currently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565f3889",
   "metadata": {},
   "outputs": [],
   "source": [
    "Semester = {'Summer 2020': \"'SSR_CSTRMPRV_VW_DESCR$8'\",\n",
    "            'Fall 2020': \"'SSR_CSTRMPRV_VW_DESCR$span$7'\",\n",
    "            'Spring 21': \"'SSR_CSTRMPRV_VW_DESCR$span$6'\",\n",
    "            'Summer 21': \"'SSR_CSTRMPRV_VW_DESCR$5'\",\n",
    "            'Fall 21': \"'SSR_CSTRMPRV_VW_DESCR$4'\",\n",
    "            'Spring 22': \"'SSR_CSTRMPRV_VW_DESCR$span$3'\",\n",
    "            'Summer 22': \"'SSR_CSTRMPRV_VW_DESCR$2'\",\n",
    "            'Fall 22': \"'SSR_CSTRMPRV_VW_DESCR$1'\",\n",
    "            'Spring 23': \"'SSR_CSTRMPRV_VW_DESCR$0'\",\n",
    "            'Summer 23': \"'SSR_CSTRMCUR_VW_DESCR$0'\", \n",
    "            'Fall 23': \"'SSR_CSTRMCUR_VW_DESCR$1'\",\n",
    "           'Spring 24': \"'SSR_CSTRMCUR_VW_DESCR$2'\",\n",
    "           'Summer 24': \"'SSR_CSTRMCUR_VW_DESCR$3'\"}\n",
    "Semester = {\n",
    "    'Current': \"'SSR_CSTRMCUR_VW_DESCR$0'\",\n",
    "    'next': \"'SSR_CSTRMCUR_VW_DESCR$1'\"\n",
    "}\n",
    "\n",
    "            \n",
    "url = f\"javascript:submitAction_win0(document.win0,{Semester['Current']});\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee77f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.execute_script(url);\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2741da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "element = driver.find_element(By.ID, 'MSU_CLSRCH_WRK2_SUBJECT')  \n",
    "element.send_keys(\"CMSE\") #pick cmse for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4c4c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"javascript:submitAction_win0(document.win0,'MSU_CLSRCH_WRK_SSR_PB_SEARCH');\"\n",
    "driver.execute_script(url);\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86be9395",
   "metadata": {},
   "source": [
    "Function to get basic classes' info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e64286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_info(soup):\n",
    "    '''Scrape entire page for all of the class boxes'''\n",
    "    values = []\n",
    "    divs = soup.find_all(\"div\", class_=\"ps-htmlarea\")\n",
    "    for div in divs:\n",
    "        val = (div.get_text(strip=True))\n",
    "        values.append(val)\n",
    "    values.pop(0)\n",
    "    del values[0]\n",
    "    #TODO: Fix this hard coded deletions\n",
    "    for i in range(5,len(values),10):\n",
    "        values[i] = 'delete'\n",
    "        values[i+1] = 'delete'\n",
    "        values[i+2] = 'delete'\n",
    "        values[i+3] = 'delete'\n",
    "    values = list(filter(lambda x: x != \"delete\", values))   \n",
    "    reshaped_list = [values[i:i+6] for i in range(0, len(values), 6)]\n",
    "    # Create a DataFrame from the reshaped list\n",
    "    col_names = ['Instructor', 'Course', 'Type', 'Section', 'Schedule', 'Dates']\n",
    "    df = pd.DataFrame(reshaped_list, columns=col_names)\n",
    "    df[['Course Code', 'Course Name']] = df['Course'].str.split(':', n=1, expand=True)\n",
    "    #df[['Type', 'Units']] = df['Type'].str.split('(', 1, expand=True)\n",
    "    split_result = df['Type'].str.split('(', n=1, expand=True)\n",
    "\n",
    "    # Check if the split operation resulted in two columns\n",
    "    if len(split_result.columns) == 2:\n",
    "        df[['Type', 'Units']] = split_result\n",
    "    else:\n",
    "        # Handle the case where the split didn't result in two columns\n",
    "        df['Type'] = split_result[0]  # Assign the first part to 'Type'\n",
    "        df['Units'] = '' \n",
    "    df[['Section', 'Class Nbr', 'Academic Session']] = df['Section'].str.split('/', n=2, expand=True)\n",
    "    df[['Days', 'Time']] = df['Schedule'].str.split(':', n=1, expand=True)\n",
    "    df[['Units','Status']] = df['Units'].str.split(')',n=1,expand=True)\n",
    "    df[['Subject','Course Number']] = df['Course Code'].str.split(' ',n=1,expand=True)\n",
    "\n",
    "    df = df.drop(['Course', 'Schedule','Course Code','Instructor'], axis=1)\n",
    "    df = df[['Subject','Course Number','Course Name','Type','Units','Status','Section','Class Nbr','Academic Session','Days','Time','Dates']]\n",
    "    df['Units'] = df['Units'].str.extract(r'(\\d+(?:\\.\\d+)?)')\n",
    "    df['Section'] = df['Section'].str.extract(r'(\\d+(?:\\.\\d+)?)')\n",
    "    df['Class Nbr'] = df['Class Nbr'].str.extract(r'(\\d+(?:\\.\\d+)?)')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751620d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "body = driver.page_source\n",
    "soup = BeautifulSoup(body, 'html.parser')\n",
    "df = get_class_info(soup)  # getting info on the first page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2af2770-3a68-4173-94f9-ad605b38c6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove none\n",
    "df = df[df['Course Name'].notna()]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a52630-19df-4ae9-9349-cd1d8a50c52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f68905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of results\n",
    "result_element = soup.find('span', id='MSU_RSLT_NAV_WK_PTPG_ROWS_GRID')\n",
    "# Extract the text content\n",
    "result_text = result_element.get_text(strip=True)\n",
    "result = int(result_text.split()[0])\n",
    "pages = (result + 49) // 50# get the number of aggregated pages\n",
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2560190f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_advanced_info(soup):\n",
    "    loc = None\n",
    "    email = None\n",
    "    name = None\n",
    "    values = []\n",
    "    divs = soup.find_all(\"div\", class_=\"ps-htmlarea\")\n",
    "    for div in divs:\n",
    "        val = (div.get_text(strip=True))\n",
    "        values.append(val)\n",
    "    values = list(filter(lambda x: x != \"\", values))\n",
    "    if len(values) > 5 and values[5] != \"\":\n",
    "        string = values[5].split('Instructor:')\n",
    "    else:\n",
    "        return None, None, None\n",
    "    loc = string[0]\n",
    "    a_elements = soup.find_all('a')\n",
    "    for a_element in a_elements:\n",
    "        # Check if the 'href' attribute exists\n",
    "        if 'href' in a_element.attrs:\n",
    "            # Check if the href attribute contains \"mailto:\"\n",
    "            if 'mailto:' in a_element['href']:\n",
    "                # Extract the email address from the href attribute\n",
    "                email = a_element['href'].split(':')[1]\n",
    "                name = a_element.text\n",
    "                break\n",
    "    return loc, email, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314505a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_info(df):\n",
    "    '''Function to add info from the breakout windows for each course\n",
    "    '''\n",
    "    location = []\n",
    "    emails = []\n",
    "    names = []\n",
    "    for i in range(len(df)):\n",
    "        rowname = f\"DESCR100$0_row_{i}\"\n",
    "        print(rowname)\n",
    "        element = driver.find_element(By.ID, rowname) \n",
    "        element.click()\n",
    "        time.sleep(2)\n",
    "        driver.switch_to.frame(0)\n",
    "        body = driver.page_source\n",
    "        soup = BeautifulSoup(body, 'html.parser')\n",
    "        loc, email, name = get_advanced_info(soup)\n",
    "        location.append(loc)\n",
    "        emails.append(email)\n",
    "        names.append(name)\n",
    "        cancel_cmd=\"javascript:doUpdateParent(document.win0,'#ICCancel');\"\n",
    "        driver.execute_script(cancel_cmd);\n",
    "        driver.switch_to.default_content();\n",
    "        time.sleep(2)\n",
    "    df['Location'] = location\n",
    "    df['email'] = emails\n",
    "    df['Instructor'] = names\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27da63f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_info(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616a44f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,pages):\n",
    "    button = driver.find_element(By.ID, 'MSU_RSLT_NAV_WK_SEARCH_CONDITION2')\n",
    "    button.click()\n",
    "    time.sleep(2)\n",
    "    body = driver.page_source\n",
    "    soup = BeautifulSoup(body, 'html.parser')\n",
    "    df_new = get_class_info(soup)\n",
    "    df_new = add_info(df_new)\n",
    "    df = df.append(df_new, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89239a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_empty_with_none(value):\n",
    "    return None if pd.isna(value) or (isinstance(value, str) and value == '') else value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bf8307",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Approval Required'] = df['Dates'].apply(lambda x: 'Yes' if 'Approval Required' in x else 'No')\n",
    "df['Dates'] = df['Dates'].str.replace('Approval Required', '').str.strip()\n",
    "# Create a new column \"Approval Required\" with \"Yes\" for rows where \"Dates\" originally contained \"Approval Required,\" and \"No\" otherwise\n",
    "\n",
    "df[['first_name','last_name']] = df['Instructor'].str.split(' ',n=1,expand=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4996f859",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['net_id'] = df['email'].str.split('@').str[0]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91075c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.applymap(replace_empty_with_none)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09181d0",
   "metadata": {},
   "source": [
    "Convert to CSV if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7464ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Spring2024.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508a9055",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
