{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91802f7b-2f5c-47b8-b9ce-bebd2e3e78b5",
   "metadata": {},
   "source": [
    "# Dynamic Web scraper\n",
    "\n",
    "This notebook scrapes the MSU courses website. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3446b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load selinimum and automatically install the Chrome Driver\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver import FirefoxOptions\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from getpass import getpass\n",
    "\n",
    "from Login import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cbc555-5bb9-4f10-9c21-cc7c65aacefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = get_driver('Firefox') # This might takes a while to boot up\n",
    "time.sleep(5)\n",
    "wait = WebDriverWait(driver, 10)\n",
    "login_to_SIS(driver)\n",
    "semesters_list, previous_semesters, current_semesters = get_semesters_list(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ba5483-1d23-4fbd-a58e-de06009702bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_info(driver, element):\n",
    "    '''Function to add info from the breakout windows for each course\n",
    "    '''\n",
    "    print(element.get_attribute('id'))\n",
    "    driver.execute_script(\"arguments[0].click();\", element) # Click on cell\n",
    "    wait.until(EC.frame_to_be_available_and_switch_to_it(0)) # Switch to Class Description frame\n",
    "    wait.until(EC.element_to_be_clickable((By.ID, \"MSU_CLS_DTL_WK2_SSR_CL_DTLS_LFF$5$_LBL\"))) # Wait until Availability is clickable\n",
    "    \n",
    "    schedule_ls = []\n",
    "    for i in range(3): # Find the class schedules, there might be multiple\n",
    "        try:\n",
    "            div = driver.find_element(By.XPATH, f\"//div[@id='win9divMSU_CLS_DTL_WK2_HTMLAREA1$160$${i}']\")\n",
    "        except:\n",
    "            break\n",
    "        schedule_ls.append(div)\n",
    "        \n",
    "    date_tds = driver.find_elements(By.XPATH, \"//td[@class='ps_grid-cell E_HTMLAREA2']\") # Find class dates\n",
    "    loc_ins_tds = driver.find_elements(By.XPATH, \"//td[@class='ps_grid-cell E_HTMLAREA3']\") # Find class locations, instructors, and modes\n",
    "    \n",
    "    schedules = []\n",
    "    dates = []\n",
    "    locs = []\n",
    "    modes = []\n",
    "    names = []\n",
    "    emails = []\n",
    "    for i in range(len(loc_ins_tds)):\n",
    "        # Append multiple schedules to a list\n",
    "        schedules.append(schedule_ls[i].text)\n",
    "        \n",
    "        # Append multiple dates to a list\n",
    "        dates.append(date_tds[i].text)\n",
    "\n",
    "        # Append multiple locations and modes to lists\n",
    "        locs.append(loc_ins_tds[i].text.split('\\n')[0])\n",
    "        modes.append(loc_ins_tds[i].text.split('\\n')[-1])\n",
    "\n",
    "        # Append multiple professors in different schedules to lists\n",
    "        a_elements = loc_ins_tds[i].find_elements(By.TAG_NAME, \"a\")\n",
    "        if not a_elements:\n",
    "            continue\n",
    "        email_ind = ''\n",
    "        name_ind = ''\n",
    "        for a_element in a_elements: # If one schedule of the class has more than 1 professor, separate with '\\n'\n",
    "            # Extract the email address from the href attribute\n",
    "            email_ind += a_element.get_attribute('href').split(':')[1] + '\\n'\n",
    "            name_ind += a_element.text + '\\n'\n",
    "        emails.append(email_ind.strip())\n",
    "        names.append(name_ind.strip())\n",
    "\n",
    "    element = driver.find_element(By.ID, \"MSU_CLS_DTL_WK2_SSR_CL_DTLS_LFF$5$_LBL\") \n",
    "    element.click() # Click on Availability \n",
    "    wait.until(EC.visibility_of_element_located((By.ID, \"win9divMSU_CLS_DTL_WK2_HTMLAREA6$22$$0\")))\n",
    "\n",
    "    avails = []\n",
    "    for i in range(10):\n",
    "        try: \n",
    "            element = driver.find_element(By.ID, f\"win9divMSU_CLS_DTL_WK2_HTMLAREA6$22$${i}\")\n",
    "            avails.append(element.text)\n",
    "        except: \n",
    "            break\n",
    "    \n",
    "    if len(avails) > 1:\n",
    "        enrolled = avails.pop()\n",
    "        limit = sum([int(x.split('/')[-1]) for x in avails])\n",
    "        avails = [enrolled + '/' + str(limit) + '*']\n",
    "    \n",
    "    cancel_cmd=\"javascript:doUpdateParent(document.win9,'#ICCancel');\" \n",
    "    driver.execute_script(cancel_cmd); # Close the frame\n",
    "    driver.switch_to.default_content(); # Switch to the main page\n",
    "    time.sleep(1.5) # More time for browser to adapt\n",
    "    \n",
    "    return [schedules, dates, locs, modes, names, emails, avails[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e93594-a4f8-4f23-a6d2-f2e7239de857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(driver):\n",
    "    '''Scrape entire page for all of the class boxes'''\n",
    "    try:\n",
    "        per_page = int(driver.find_element(By.ID, 'MSU_RSLT_NAV_WK_NUM2').text)\n",
    "        result_element = driver.find_element(By.ID, 'MSU_RSLT_NAV_WK_PTPG_ROWS_GRID').text\n",
    "        result = int(result_element.split()[0])\n",
    "        pages = (result + per_page - 1) // per_page # get the number of aggregated pages\n",
    "    except:\n",
    "        pages = 1\n",
    "        \n",
    "    reshaped_list = []\n",
    "    counter = 1\n",
    "    while True:\n",
    "        cells = driver.find_elements(By.XPATH, \"//tr[@class='ps_grid-row psc_rowact']\") # Find all table row in the page (Classes)\n",
    "        for cell in cells:\n",
    "            values = cell.text.split(\"\\n\") # Split text in a cell\n",
    "            if values[1].split(')')[-1] == '':\n",
    "                removed = values.pop(2)\n",
    "                values[1] += removed\n",
    "            values = values[:3] + add_info(driver, cell) # Get all other info\n",
    "            reshaped_list.append(values) \n",
    "        if counter == pages:\n",
    "            break\n",
    "        url = f\"javascript:submitAction_win9(document.win9,'MSU_RSLT_NAV_WK_SEARCH_CONDITION2$46$');\"\n",
    "        driver.execute_script(url) # If there's more pages, click Next\n",
    "        time.sleep(3)\n",
    "        print(\"Next page\")\n",
    "        counter += 1\n",
    "    \n",
    "    col_names = ['Course', 'Type', 'Section', 'Schedule', 'Dates', 'Location', \n",
    "                 'Mode', 'Instructor', 'Email', 'Availability']\n",
    "    df = pd.DataFrame(reshaped_list, columns=col_names)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6446fc-5b56-417c-8fa2-39183dc190f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_courses_df(df): \n",
    "    # Explode all these columns, will result in duplicate rows for classes that have multiple schedules\n",
    "    try: \n",
    "        df = df.explode(['Schedule', 'Dates', 'Location', 'Mode', 'Email', 'Instructor'])\n",
    "    except: # In cases every class doesn't have an instructor\n",
    "        df = df.explode(['Schedule', 'Dates', 'Location', 'Mode'])\n",
    "        df = df.explode(['Email', 'Instructor'])\n",
    "    try: \n",
    "        df[['Days', 'Time']] = df['Schedule'].str.split(':',n=1,expand=True)\n",
    "    except: # In case every classes' schedule is 'To Be Announced'\n",
    "        df[['Days', 'Time']] = np.nan, np.nan\n",
    "    df[['Course Code', 'Course Name']] = df['Course'].str.split(':', n=1, expand=True)  \n",
    "    split_result = df['Type'].str.split('(', n=1, expand=True)\n",
    "    # Check if the split operation resulted in two columns\n",
    "    if len(split_result.columns) == 2:\n",
    "        df[['Type', 'Units']] = split_result\n",
    "    else:\n",
    "        # Handle the case where the split didn't result in two columns\n",
    "        df['Type'] = split_result[0]  # Assign the first part to 'Type'\n",
    "        df['Units'] = '' \n",
    "    df[['Section', 'Class Nbr', 'Academic Session']] = df['Section'].str.split('/', n=2, expand=True)\n",
    "    df[['Units','Status']] = df['Units'].str.split(')', n=1, expand=True)\n",
    "    df[['Subject','Course Number']] = df['Course Code'].str.split(' ',n=1,expand=True)\n",
    "    df['Dates'] = df['Dates'].apply(lambda x: x.replace(\"Approval Required\", '').strip() if not pd.isna(x) else x)\n",
    "    df['Status'] = df['Status'].str.replace('Reserved Capacity', '').str.strip()\n",
    "    \n",
    "    df['Course Name'] = df['Course Name'].apply(lambda x: x.replace('Approval Required', '') if not pd.isna(x) else x)\n",
    "    df['Course Name'] = df['Course Name'].apply(lambda x: x.replace('Cross-Listed', '') if not pd.isna(x) else x)\n",
    "\n",
    "    df = df.drop(['Course', 'Schedule','Course Code'], axis=1)\n",
    "    df = df[['Subject','Course Number','Course Name','Type','Units','Status',\n",
    "             'Section','Class Nbr','Academic Session','Days','Time','Dates', \n",
    "             'Location', 'Mode', 'Email', 'Instructor', 'Availability']]\n",
    "    df['Units'] = df['Units'].str.replace(' units', '')\n",
    "    df['Section'] = df['Section'].str.extract(r'(\\d+(?:\\.\\d+)?)')\n",
    "    df['Class Nbr'] = df['Class Nbr'].str.extract(r'(\\d+(?:\\.\\d+)?)')\n",
    "\n",
    "    df = df.map(lambda x: np.nan if not pd.isna(x) and 'Instructor:' in x else x)\n",
    "    df.replace(['To Be Announced', 'Arranged', 'No room - Prof will arrange'], np.nan, inplace=True)\n",
    "    df = df.groupby(df.index).agg(lambda x: list(x)) # Combining rows with same index into list\n",
    "    df = df.map(lambda ls: [x for x in ls if not pd.isna(x)] if len(ls) > 1 else ls) # Dropping pd.NA in all lists in row \n",
    "    df = df.map(lambda ls: ls[0] if len(ls) == 1 or len(set(ls)) == 1 else ls) # Getting rid of redundancy in lists in row\n",
    "    df = df.map(lambda x: np.nan if x == [] else x)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4beaa6a-8f1e-4cc9-89dd-8eb285bae142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_by_semester(driver, search_semester):\n",
    "    switch_to_semester(driver, search_semester, previous_semesters)\n",
    "    element = driver.find_element(By.ID, 'MSU_CLSRCH_WRK2_SUBJECT')  \n",
    "    element.send_keys(\"CMSE\") #pick cmse for example\n",
    "    url = f\"javascript:submitAction_win9(document.win9,'MSU_CLSRCH_WRK_SSR_PB_SEARCH');\"\n",
    "    driver.execute_script(url); # Hit search\n",
    "    wait.until(EC.element_to_be_clickable((By.ID, 'DESCR100$0_row_0')))\n",
    "        \n",
    "    df = get_info(driver)\n",
    "    df = reformat_courses_df(df)\n",
    "    return df\n",
    "\n",
    "df = scrape_by_semester(driver, 'Fall Semester 2024')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ebd499-fc89-4b8f-a0fd-745fbf480ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Fall2024.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
